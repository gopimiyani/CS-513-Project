{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "from tqdm import tqdm_notebook \n",
    "import seaborn as sns\n",
    "import imageio\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFSN_MultiClass: #Class for Feed-Forward Noural Network \n",
    "  \n",
    "  def __init__(self, n_inputs, n_outputs, hidden_sizes=[3]):\n",
    "    self.nx = n_inputs\n",
    "    self.ny = n_outputs\n",
    "    self.nh = len(hidden_sizes)\n",
    "    self.sizes = [self.nx] + hidden_sizes + [self.ny] \n",
    "\n",
    "    self.W = {}\n",
    "    self.B = {}\n",
    "    for i in range(self.nh+1):\n",
    "      self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
    "      self.B[i+1] = np.random.randn(1, self.sizes[i+1])\n",
    "      \n",
    "  def sigmoid(self, x): # Sigmoid Function\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "  \n",
    "  def softmax(self, x): # Softmax Function for O/P\n",
    "    exps = np.exp(x)\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "  def forward_pass(self, x): # Forward Pass \n",
    "    self.A = {}\n",
    "    self.H = {}\n",
    "    self.H[0] = x.reshape(1, -1)\n",
    "    for i in range(self.nh):\n",
    "      self.A[i+1] = np.matmul(self.H[i], self.W[i+1]) + self.B[i+1]\n",
    "      self.H[i+1] = self.sigmoid(self.A[i+1])\n",
    "    self.A[self.nh+1] = np.matmul(self.H[self.nh], self.W[self.nh+1]) + self.B[self.nh+1]\n",
    "    self.H[self.nh+1] = self.softmax(self.A[self.nh+1])\n",
    "    return self.H[self.nh+1]\n",
    "  \n",
    "  def predict(self, X): # Predict Function (Forward Pass)\n",
    "    Y_pred = []\n",
    "    for x in X:\n",
    "      y_pred = self.forward_pass(x)\n",
    "      Y_pred.append(y_pred)\n",
    "    return np.array(Y_pred).squeeze()\n",
    " \n",
    "  def grad_sigmoid(self, x): #Gradient of Sigmoid Function\n",
    "    return x*(1-x) \n",
    "  \n",
    "  def cross_entropy(self,label,pred): # Entropy Loss Calculations\n",
    "    yl=np.multiply(pred,label)\n",
    "    yl=yl[yl!=0]\n",
    "    yl=-np.log(yl)\n",
    "    yl=np.mean(yl)\n",
    "    return yl\n",
    " \n",
    "  def grad(self, x, y): # Gradient Calculation\n",
    "    self.forward_pass(x)\n",
    "    self.dW = {}\n",
    "    self.dB = {}\n",
    "    self.dH = {}\n",
    "    self.dA = {}\n",
    "    L = self.nh + 1\n",
    "    self.dA[L] = (self.H[L] - y)\n",
    "    for k in range(L, 0, -1):\n",
    "      self.dW[k] = np.matmul(self.H[k-1].T, self.dA[k])\n",
    "      self.dB[k] = self.dA[k]\n",
    "      self.dH[k-1] = np.matmul(self.dA[k], self.W[k].T)\n",
    "      self.dA[k-1] = np.multiply(self.dH[k-1], self.grad_sigmoid(self.H[k-1])) \n",
    "    \n",
    "  def fit(self, X, Y, epochs=100, initialize='True', learning_rate=0.01, display_loss=False): # Fit Function (For Training)\n",
    "      \n",
    "    if display_loss:\n",
    "      loss = {}\n",
    "      \n",
    "    if initialize:\n",
    "      for i in range(self.nh+1):\n",
    "        self.W[i+1] = np.random.randn(self.sizes[i], self.sizes[i+1])\n",
    "        self.B[i+1] = np.zeros((1, self.sizes[i+1]))\n",
    "        \n",
    "    for epoch in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
    "      dW = {}\n",
    "      dB = {}\n",
    "      for i in range(self.nh+1):\n",
    "        dW[i+1] = np.zeros((self.sizes[i], self.sizes[i+1]))\n",
    "        dB[i+1] = np.zeros((1, self.sizes[i+1]))\n",
    "      for x, y in zip(X, Y):\n",
    "        self.grad(x, y)\n",
    "        for i in range(self.nh+1):\n",
    "          dW[i+1] += self.dW[i+1]\n",
    "          dB[i+1] += self.dB[i+1]\n",
    "                  \n",
    "      m = X.shape[1]\n",
    "      for i in range(self.nh+1):\n",
    "        self.W[i+1] -= learning_rate * (dW[i+1]/m)\n",
    "        self.B[i+1] -= learning_rate * (dB[i+1]/m)\n",
    "        \n",
    "      if display_loss:\n",
    "        Y_pred = self.predict(X) \n",
    "        loss[epoch] = self.cross_entropy(Y, Y_pred)\n",
    "    \n",
    "    if display_loss:\n",
    "      plt.plot(loss.values())\n",
    "      plt.xlabel('Epochs')\n",
    "      plt.ylabel('CE')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Dataset\n",
    "data = pd.read_csv('Final_Refined_Encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the Price according to FNN\n",
    "bins = [1, 2, 3, 4]\n",
    "#bins = [0, 50, 150, 250, 500, 1000]\n",
    "names = [0, 1, 2, 3]\n",
    "\n",
    "label_dict = dict(enumerate(names, 1))\n",
    "price = pd.Series(np.vectorize(label_dict.get)(np.digitize(data['Price'], bins)))\n",
    "#price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'] = price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saperating the Target Column\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard-Scalar\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding the output categories\n",
    "enc = OneHotEncoder()\n",
    "# 1 -> (1, 0, 0, 0, 0, 0), 2 -> (0, 1, 0, 0, 0, 0), 3 -> (0, 0, 1, 0, 0, 0), 4 -> (0, 0, 0, 1, 0, 0), 5 -> (0, 0, 0, 0, 1, 0), 6-> (0, 0, 0, 0, 1, 0) \n",
    "y_OH_train = enc.fit_transform(np.expand_dims(y_train,1)).toarray()\n",
    "y_OH_val = enc.fit_transform(np.expand_dims(y_test,1)).toarray()\n",
    "print(y_OH_train.shape, y_OH_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Innitilization & Training\n",
    "ffsn_multi = FFSN_MultiClass(102,4,[102,50])\n",
    "ffsn_multi.fit(X_train,y_OH_train,epochs=10000,learning_rate=.005,display_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting and Accuracy Calculation\n",
    "Y_pred_train = ffsn_multi.predict(X_train)\n",
    "Y_pred_train = np.argmax(Y_pred_train,1)\n",
    "\n",
    "Y_pred_val = ffsn_multi.predict(X_test)\n",
    "Y_pred_val = np.argmax(Y_pred_val,1)\n",
    "\n",
    "accuracy_train = accuracy_score(Y_pred_train, y_train)\n",
    "accuracy_val = accuracy_score(Y_pred_val, y_test)\n",
    "\n",
    "print(\"Training accuracy\", round(accuracy_train, 2))\n",
    "print(\"Validation accuracy\", round(accuracy_val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
